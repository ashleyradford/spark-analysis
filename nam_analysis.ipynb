{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a17308dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, desc, asc, when\n",
    "import pyspark.sql.functions as F\n",
    "import pygeohash as pgh\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "geohashEncodeUDF = F.udf(lambda x, y: pgh.encode(x, y))\n",
    "geohashDecodeUDF = F.udf(lambda s: pgh.decode(s))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1f0822",
   "metadata": {},
   "source": [
    "### Strangely Snowy: Find a location that contains snow while its surroundings do not. Why does this occur? Is it a high mountain peak in a desert?\n",
    "I originally started by looking for all the points in the dataset on Dec 26th, 2016 that had snow and realized there were too many points to look at them all individually. So I looked up a map that let me pick a point and get the lat and long values for the point and picked a spot in Arizona because some areas have snow in winter, but that didn't give me many results so I started looking in the CA/NV border because of the mountain ranges in the area.\n",
    "\n",
    "I found an area in the Stanislaus National Forest between December 26-29, 2016 that had only one point in a bounding region with a snow depth higher than 0. The area's bounding latitude values were between 37.3-37.8, and its bounding longitude values were -121 and -120. \n",
    "The coordinates of the snowy point are 38.021557396033124 lat and -120.00482559776982 long.\n",
    "The elevation of this point is 4996.6 ft, so it makes sense that the surrounding points with lower elevation would have no snow on them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a0b5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.load('hdfs://orion01:25001/namanl_218_20151010_0000_003.grb.tdv.gz',\n",
    "                     format='csv',\n",
    "                     sep='\\t',\n",
    "                     inferSchema='true',\n",
    "                     header='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f69d8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91491e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95928124",
   "metadata": {},
   "outputs": [],
   "source": [
    "snowy = df.filter(df.snow_depth_surface > 0)\n",
    "snowy.take(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128da606",
   "metadata": {},
   "outputs": [],
   "source": [
    "snowy.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a76f8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"total\")\n",
    "\n",
    "arizona = spark.sql('SELECT * FROM total WHERE 2_lat > 32 AND 2_lat < 34 AND 3_lon > -111 AND 3_lon < -109 AND snow_depth_surface == 0')\n",
    "\n",
    "# around = snowy.filter(df.2_lat >= 32 && df.2_lat >= 34).filter(df.3_lon >= -109 && df.3_lon >= -111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81dce29",
   "metadata": {},
   "outputs": [],
   "source": [
    "arizona.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55bf5dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "arizona.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9120c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "diablo = spark.sql('SELECT * FROM total WHERE 2_lat > 35 AND 2_lat < 38 AND 3_lon > 120 AND 3_lon < 123 AND snow_depth_surface > 0')\n",
    "diablo.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72dc0094",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  namanl_218_20161227_1200_003.grb.tdv.gz\n",
    "dec27 = spark.read.load('hdfs://orion01:25001/namanl_218_201612*.gz',\n",
    "                     format='csv',\n",
    "                     sep='\\t',\n",
    "                     inferSchema='true',\n",
    "                     header='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c666fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "dec27.createOrReplaceTempView(\"december\")\n",
    "\n",
    "wovoka_snow = spark.sql('SELECT * FROM december WHERE 2_lat > 37.5 AND 2_lat < 38.5 AND 3_lon < -118 AND 3_lon > -121 AND snow_depth_surface > 0')\n",
    "wovoka_dry = spark.sql('SELECT * FROM december WHERE 2_lat > 37.5 AND 2_lat < 38.5 AND 3_lon < -118 AND 3_lon > -121 AND snow_depth_surface = 0')\n",
    "\n",
    "wovoka = spark.sql('SELECT 2_lat, 3_lon, snow_depth_surface FROM december WHERE 2_lat > 37.5 AND 2_lat < 38.5 AND 3_lon < -118 AND 3_lon > -121')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42d21e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "wovoka_snow.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e962703",
   "metadata": {},
   "outputs": [],
   "source": [
    "wovoka_dry.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb2b3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "wovoka.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1d4469",
   "metadata": {},
   "outputs": [],
   "source": [
    "wovoka.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c8e2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "wovoka.take(75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb12684",
   "metadata": {},
   "outputs": [],
   "source": [
    "dec27.createOrReplaceTempView(\"wovoka\")\n",
    "\n",
    "bound = spark.sql('SELECT 2_lat, 3_lon, snow_depth_surface FROM wovoka WHERE 37.3 < 2_lat AND 2_lat < 38.1 AND -121 < 3_lon AND 3_lon < -120')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb18ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "bound.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00af1a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "bound.take(168)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325864a8",
   "metadata": {},
   "source": [
    "#### Climate Chart: Given a Geohash prefix as an input, build a function that will create a climate chart for the region. This includes high, low, and average temperatures, as well as monthly average rainfall (precipitation).\n",
    "\n",
    "To solve this problem, I imported a few days worth of data from every month in 2016 so that any random fluctuations in weather by week would be accounted for. I then added a column of geohashes so that I could select only the points in each month's dataframes that started with the 2 character geohash, as well as renamed the lat and lon columns to make calculating the geohashes go more smoothly.\n",
    "\n",
    "My next step was to make a function that would get the necessary data from each of the month dataframes, average them, and then store them in another dataframe that could be saved into a file. This file is read by the chart function that was linked in the project spec, though I did modify it slightly so that it treated the temperatures as though they were in Fahrenheit by default. The charting method then reads teh file and plots teh high, low, and average temperatures per month, as well as the average rainfall per month in inches (the numbers are pretty low, but I think I just chose days that didn't have as much rain...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ade28ccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "jan = spark.read.load('hdfs://orion01:25001/namanl_218_201601*.gz',\n",
    "                     format='csv',\n",
    "                     sep='\\t',\n",
    "                     inferSchema='true',\n",
    "                     header='true')\n",
    "\n",
    "feb = spark.read.load('hdfs://orion01:25001/namanl_218_201602*.gz',\n",
    "                     format='csv',\n",
    "                     sep='\\t',\n",
    "                     inferSchema='true',\n",
    "                     header='true')\n",
    "\n",
    "mar = spark.read.load('hdfs://orion01:25001/namanl_218_201603*.gz',\n",
    "                     format='csv',\n",
    "                     sep='\\t',\n",
    "                     inferSchema='true',\n",
    "                     header='true')\n",
    "\n",
    "apr = spark.read.load('hdfs://orion01:25001/namanl_218_201604*.gz',\n",
    "                     format='csv',\n",
    "                     sep='\\t',\n",
    "                     inferSchema='true',\n",
    "                     header='true')\n",
    "\n",
    "may = spark.read.load('hdfs://orion01:25001/namanl_218_201605*.gz',\n",
    "                     format='csv',\n",
    "                     sep='\\t',\n",
    "                     inferSchema='true',\n",
    "                     header='true')\n",
    "\n",
    "jun = spark.read.load('hdfs://orion01:25001/namanl_218_201606*.gz',\n",
    "                     format='csv',\n",
    "                     sep='\\t',\n",
    "                     inferSchema='true',\n",
    "                     header='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7f0947b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "jul = spark.read.load('hdfs://orion01:25001/namanl_218_201607*.gz',\n",
    "                     format='csv',\n",
    "                     sep='\\t',\n",
    "                     inferSchema='true',\n",
    "                     header='true')\n",
    "\n",
    "aug = spark.read.load('hdfs://orion01:25001/namanl_218_201608*.gz',\n",
    "                     format='csv',\n",
    "                     sep='\\t',\n",
    "                     inferSchema='true',\n",
    "                     header='true')\n",
    "\n",
    "sep = spark.read.load('hdfs://orion01:25001/namanl_218_201609*.gz',\n",
    "                     format='csv',\n",
    "                     sep='\\t',\n",
    "                     inferSchema='true',\n",
    "                     header='true')\n",
    "\n",
    "octo = spark.read.load('hdfs://orion01:25001/namanl_218_201610*.gz',\n",
    "                     format='csv',\n",
    "                     sep='\\t',\n",
    "                     inferSchema='true',\n",
    "                     header='true')\n",
    "\n",
    "nov = spark.read.load('hdfs://orion01:25001/namanl_218_201611*.gz',\n",
    "                     format='csv',\n",
    "                     sep='\\t',\n",
    "                     inferSchema='true',\n",
    "                     header='true')\n",
    "\n",
    "dec = spark.read.load('hdfs://orion01:25001/namanl_218_201612*.gz',\n",
    "                     format='csv',\n",
    "                     sep='\\t',\n",
    "                     inferSchema='true',\n",
    "                     header='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302b0086",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a1360cea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(time=1452697200000, lat=37.03410173798036, lon=-86.05695551596708, albedo_surface=15.25, precipitable_water_entire_atmosphere_single_layer='null', pressure_maximum_wind=19526.98, pressure_surface=100037.0, pressure_tropopause=21726.576, relative_humidity_zerodegc_isotherm=66.0, snow_depth_surface=0.0, temperature_surface=270.7961, temperature_tropopause=213.32837, total_cloud_cover_entire_atmosphere_single_layer='null', total_precipitation_surface_3_hour_accumulation=0.0, vegetation_surface=30.25, visibility_surface=24229.455, wilting_point_surface=0.083749995, wind_speed_gust_surface='null', _c18=None, geohash='dndf9tz5r8gj')]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "jan = jan.withColumnRenamed(\"1_time\", \"time\").withColumnRenamed(\"2_lat\", \"lat\").withColumnRenamed(\"3_lon\", \"lon\")\n",
    "jan = jan.withColumn(\"geohash\", geohashEncodeUDF(jan.lat, jan.lon))\n",
    "\n",
    "feb = feb.withColumnRenamed(\"1_time\", \"time\").withColumnRenamed(\"2_lat\", \"lat\").withColumnRenamed(\"3_lon\", \"lon\")\n",
    "feb = feb.withColumn(\"geohash\", geohashEncodeUDF(feb.lat, feb.lon))\n",
    "\n",
    "mar = mar.withColumnRenamed(\"1_time\", \"time\").withColumnRenamed(\"2_lat\", \"lat\").withColumnRenamed(\"3_lon\", \"lon\")\n",
    "mar = mar.withColumn(\"geohash\", geohashEncodeUDF(mar.lat, mar.lon))\n",
    "\n",
    "apr = apr.withColumnRenamed(\"1_time\", \"time\").withColumnRenamed(\"2_lat\", \"lat\").withColumnRenamed(\"3_lon\", \"lon\")\n",
    "apr = apr.withColumn(\"geohash\", geohashEncodeUDF(apr.lat, apr.lon))\n",
    "\n",
    "may = may.withColumnRenamed(\"1_time\", \"time\").withColumnRenamed(\"2_lat\", \"lat\").withColumnRenamed(\"3_lon\", \"lon\")\n",
    "may = may.withColumn(\"geohash\", geohashEncodeUDF(may.lat, may.lon))\n",
    "\n",
    "jun = jun.withColumnRenamed(\"1_time\", \"time\").withColumnRenamed(\"2_lat\", \"lat\").withColumnRenamed(\"3_lon\", \"lon\")\n",
    "jun = jun.withColumn(\"geohash\", geohashEncodeUDF(jun.lat, jun.lon))\n",
    "\n",
    "jul = jul.withColumnRenamed(\"1_time\", \"time\").withColumnRenamed(\"2_lat\", \"lat\").withColumnRenamed(\"3_lon\", \"lon\")\n",
    "jul = jul.withColumn(\"geohash\", geohashEncodeUDF(jul.lat, jul.lon))\n",
    "\n",
    "aug = aug.withColumnRenamed(\"1_time\", \"time\").withColumnRenamed(\"2_lat\", \"lat\").withColumnRenamed(\"3_lon\", \"lon\")\n",
    "aug = aug.withColumn(\"geohash\", geohashEncodeUDF(aug.lat, aug.lon))\n",
    "\n",
    "sep = sep.withColumnRenamed(\"1_time\", \"time\").withColumnRenamed(\"2_lat\", \"lat\").withColumnRenamed(\"3_lon\", \"lon\")\n",
    "sep = sep.withColumn(\"geohash\", geohashEncodeUDF(sep.lat, sep.lon))\n",
    "\n",
    "octo = octo.withColumnRenamed(\"1_time\", \"time\").withColumnRenamed(\"2_lat\", \"lat\").withColumnRenamed(\"3_lon\", \"lon\")\n",
    "octo = octo.withColumn(\"geohash\", geohashEncodeUDF(octo.lat, octo.lon))\n",
    "\n",
    "nov = nov.withColumnRenamed(\"1_time\", \"time\").withColumnRenamed(\"2_lat\", \"lat\").withColumnRenamed(\"3_lon\", \"lon\")\n",
    "nov = nov.withColumn(\"geohash\", geohashEncodeUDF(nov.lat, nov.lon))\n",
    "\n",
    "dec = dec.withColumnRenamed(\"1_time\", \"time\").withColumnRenamed(\"2_lat\", \"lat\").withColumnRenamed(\"3_lon\", \"lon\")\n",
    "dec = dec.withColumn(\"geohash\", geohashEncodeUDF(dec.lat, dec.lon))\n",
    "    \n",
    "jan.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50d60ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def climate_chart(months, geohash):\n",
    "    avgs = pd.DataFrame()\n",
    "\n",
    "    avgs['month'] = None\n",
    "    avgs['h_temp'] = None\n",
    "    avgs['l_temp'] = None\n",
    "    avgs['avg_precip'] = None\n",
    "    avgs['avg_temp'] = None\n",
    "    \n",
    "    \n",
    "    for i in range(0, len(months)):\n",
    "        min_temp = months[i].select(min(when(months[i].geohash.startswith(geohash), months[i].temperature_surface)).alias(\"min_temp\"))\n",
    "        max_temp = months[i].select(max(when(months[i].geohash.startswith(geohash), months[i].temperature_surface)).alias(\"max_temp\"))\n",
    "        avg_temp = months[i].select(avg(when(months[i].geohash.startswith(geohash), months[i].temperature_surface)).alias(\"avg_temp\"))\n",
    "        avg_rain = months[i].select(avg(when(months[i].geohash.startswith(geohash), months[i].total_precipitation_surface_3_hour_accumulation)).alias(\"avg_rain\"))\n",
    "\n",
    "        # <month-num>  <high-temp>  <low-temp>  <avg-precip>  <avg-temp>\n",
    "        data = [i+1, k2f(max_temp.head().max_temp), k2f(float(min_temp.head().min_temp)), \\\n",
    "                   avg_rain.head().avg_rain, k2f(avg_temp.head().avg_temp)]\n",
    "        \n",
    "        avgs.loc[len(avgs.index)] = data\n",
    "        \n",
    "    return avgs  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6651a0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib\n",
    "from matplotlib import rc\n",
    "\n",
    "def c2f(t):\n",
    "    return (t*9/5.0)+32\n",
    "\n",
    "def k2c(t):\n",
    "    return t-273.15\n",
    "\n",
    "def k2f(t):\n",
    "    return (t*9/5.0)-459.67\n",
    "\n",
    "#------------------------------------------------------------------------------------#\n",
    "\n",
    "def climate_map(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        first_line = f.readline()[1:].strip()\n",
    "        lines = (line for line in f if not line.startswith(','))\n",
    "        data = np.loadtxt(lines, delimiter=' ')\n",
    "        \n",
    "    data = data[:, 1:]\n",
    "    \n",
    "    data[:, 0] = data[:, 0] - 1\n",
    "    data[:, 3] = data[:, 3] * 0.0393701\n",
    "\n",
    "    plt.ion()\n",
    "    plt.clf()\n",
    "    fig = plt.figure(1)\n",
    "    fig.subplots_adjust(hspace=.20)\n",
    "    gs = gridspec.GridSpec(2, 1, height_ratios=[1.75, 1])\n",
    "    ax0 = plt.subplot(gs[0])\n",
    "    ax1 = plt.subplot(gs[1], sharex=ax0)\n",
    "    plt.setp(ax0.get_xticklabels(), visible=False) # disable upper axis label\n",
    "\n",
    "    ax0.patch.set_facecolor('None')\n",
    "    ax1.patch.set_facecolor('None')\n",
    "    \n",
    "    title = \"Climate Overview\"\n",
    "\n",
    "    plt.suptitle(title, fontsize=14)\n",
    "\n",
    "    y = 0\n",
    "    ax0.plot([0, data[:, 0].max() + 1], [y, y], zorder=-1, color='#888888',\n",
    "                alpha=.75, dashes=(8, 2))\n",
    "\n",
    "    rects0 = ax0.bar(.35 + data[:, 0], data[:, 2] - data[:, 1], bottom=data[:, 1],\n",
    "            width=.6, color='#df3c3c', edgecolor='#731515')\n",
    "\n",
    "    rects1 = ax1.bar(.35 + data[:, 0], data[:, 3], color='#1b7edb', width=.6,\n",
    "            edgecolor='#1d4871')\n",
    "    \n",
    "    print(data[:,3])\n",
    "\n",
    "    plt.xticks(np.arange(0,12) + .4, ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun',\n",
    "        'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'],\n",
    "        rotation=30)\n",
    "\n",
    "    ax0.spines['left'].set_visible(True)\n",
    "    ax1.spines['left'].set_visible(True)\n",
    "\n",
    "    for tic in ax0.xaxis.get_major_ticks():\n",
    "        tic.tick1On = tic.tick2On = False\n",
    "\n",
    "    for tic in ax0.yaxis.get_major_ticks():\n",
    "        tic.tick2On = False\n",
    "\n",
    "    for tic in ax1.xaxis.get_major_ticks():\n",
    "        tic.tick1On = tic.tick2On = False\n",
    "\n",
    "    for tic in ax1.yaxis.get_major_ticks():\n",
    "        tic.tick2On = False\n",
    "\n",
    "    for rect in rects1:\n",
    "        height = rect.get_height()\n",
    "        ax1.text(rect.get_x() + rect.get_width()/2., 1.08*height,\n",
    "            '%.2f' % (height), ha='center', va='bottom', color='#1d4871')\n",
    "\n",
    "    for r, rect in enumerate(rects0):\n",
    "        height = rect.get_height()\n",
    "        print(height)\n",
    "        ax0.text(rect.get_x() + rect.get_width()/2., rect.get_y() + 1.08*height,\n",
    "            '%d' % int(height + rect.get_y()), ha='center', va='bottom',\n",
    "            color='#731515')\n",
    "        ax0.text(rect.get_x() + rect.get_width()/2., rect.get_y() - 2,\n",
    "            '%d' % int(rect.get_y()), ha='center', va='top', color='#731515')\n",
    "        ax0.plot([rect.get_x() + .05, rect.get_x() + rect.get_width() - .05],\n",
    "                [data[r, 4], data[r, 4]], color='#731515')\n",
    "\n",
    "    ax0.set_ylabel('Temperature (F)')\n",
    "    ax1.set_ylabel('Precipitation (in)')\n",
    "\n",
    "    plt.savefig('climate.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d18beb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "months = [jan, feb, mar, apr, may, jun, jul, aug, sep, octo, nov, dec]\n",
    "\n",
    "avgs = climate_chart(months=months, geohash='dj')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bbbb8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "avgs.head(12)\n",
    "# print(len(avgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bfe133",
   "metadata": {},
   "outputs": [],
   "source": [
    "avgs.to_csv('avgs.csv',sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a56add",
   "metadata": {},
   "outputs": [],
   "source": [
    "climate = climate_map('avgs.csv')\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba2e070",
   "metadata": {},
   "source": [
    "#### Fogless Mansion: After becoming rich from your startup, you are looking for the perfect location to build your Bay Area mansion with unobstructed views. Find the locations that are the least foggy and show them on a map.\n",
    "\n",
    "My first step to solve this problem was to import all of the plotting libraries from matplotlib and pandas. I then renamed the columns for latitude and longitude so that I wouldn't get errors from having ints in the column names when referencing them. I found the general latitude and longitude box for the bay area and started filtering the dataset with those values. \n",
    "\n",
    "I chose to have the ```visibility_surface``` of the point be higher than 24000m for the best visibility possible, and I found about 4400 points that way. Sadly, this set of results was not very good and when plotted gave really weird results with arcing lines of high visibility, so I scrapped it and adjusted my filter parameters.\n",
    "\n",
    "My second test added a few more files from the summer of 2016 when the fog levels would be highest between June and August rather than just July in the first time around."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6a5d4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614826ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumnRenamed(\"1_time\", \"time\").withColumnRenamed(\"2_lat\", \"lat\").withColumnRenamed(\"3_lon\", \"lon\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf810237",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c67a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"df\")\n",
    "\n",
    "clear = spark.sql('SELECT lat, lon, visibility_surface FROM df WHERE visibility_surface > 24000 \\\n",
    "                    AND 38 > lat AND lat > 37 AND 122 > lon AND 120 > 37')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6cb54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clear.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864cc8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "clear = clear.sort(\"lon\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd2c48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "clear.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5d6394",
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_df = clear.toPandas()\n",
    "\n",
    "clear_df.plot(x=\"lon\", y=\"lat\", kind=\"scatter\", c=\"visibility_surface\",\n",
    "        colormap=\"YlOrRd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b786a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "summer = spark.read.load('hdfs://orion01:25001/namanl_218_20160*0600*.gz',\n",
    "                     format='csv',\n",
    "                     sep='\\t',\n",
    "                     inferSchema='true',\n",
    "                     header='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a37494",
   "metadata": {},
   "outputs": [],
   "source": [
    "summer = summer.withColumnRenamed(\"1_time\", \"time\").withColumnRenamed(\"2_lat\", \"lat\").withColumnRenamed(\"3_lon\", \"lon\")\n",
    "\n",
    "summer.createOrReplaceTempView(\"summer\")\n",
    "\n",
    "summ = spark.sql('SELECT lat, lon, visibility_surface FROM summer WHERE 24000 > visibility_surface \\\n",
    "                    AND visibility_surface > 19000 AND 40 > lat AND lat > 36 AND -120 > lon AND lon > -125')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3595a292",
   "metadata": {},
   "outputs": [],
   "source": [
    "summ.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2e063d",
   "metadata": {},
   "outputs": [],
   "source": [
    "summ_df = summ.toPandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62b7b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "summ_df = summ_df.sort_values(by='lon', ascending=True)\n",
    "\n",
    "summ_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b7a845",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "summ.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7a2f7b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "summ_df.plot(x=\"lon\", y=\"lat\", kind=\"scatter\", c=\"visibility_surface\",\n",
    "        colormap=\"YlOrRd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b97d47c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b88042",
   "metadata": {},
   "outputs": [],
   "source": [
    "worldmap = gpd.read_file(gpd.datasets.get_path(\"naturalearth_lowres\"))\n",
    "worldmap[worldmap[\"name\"] == \"United States of America\"].plot(color=\"lightgrey\")\n",
    "\n",
    "x = summ_df['lon']\n",
    "y = summ_df['lat']\n",
    "\n",
    "plt.scatter(x, y, s=z/20000, c=z, cmap='RdPu')\n",
    "\n",
    "plt.colorbar(label='visibility_surface')\n",
    "\n",
    "plt.xlim([-128, -118])\n",
    "plt.ylim([35, 42.5])\n",
    "\n",
    "plt.xlabel(\"Longitude\")\n",
    "plt.ylabel(\"Latitude\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57508442",
   "metadata": {},
   "source": [
    "### SolarWind, Inc.: \n",
    "#### After getting rich from your travel startup you get bored and start a new company; here, you want to help power companies plan out the locations of solar and wind farms across North America. Locate the top 3 places for solar and wind farms, as well as a combination of both (solar + wind farm). You will report a total of 9 Geohashes as well as their relevant attributes (for example, cloud cover and wind speeds).\n",
    "\n",
    "For this problem, I stored all the files at 12pm for the entire 2019 data folder because there are valid `wind_speed_gust_surface` and `total_cloud_cover_entire_atmosphere_single_layer` values for 2019. I had to abandon my favorite 2016 dataset :'(\n",
    "\n",
    "The next thing I did was try a few different ranges of wind gust speeds to filter on in North America, but ultimately decided on 50-70mph so that it was still a somewhat common speed. Some geohashes that were the best for wind farms based on these critera are *9wm6619rmzpp* (69.85mph), *9vqengzgyf40* (69.91mph), and *9xhukcmqdyt8* (69.87mph), all of which were not in the middle of the ocean (because that was a susprisingly annoying problem I kept running into).\n",
    "\n",
    "I followed the same steps for cloud coverage (low cloud coverage means high sun exposure for solar panels) and eventually settled on a cloud coverage range of 0-15%. This was a bit harder to settle on because of duplicate points from all the files, but to fix that I aggreggated the average cloud coverage of all the points by geohash, this way I was sure that there was only one entry per location, and it could give a baseline estimate for yearly sun exposure. Three geohashes with low cloud coverage that could have solar energy farms are *djv29jbe3xt4* (0%), *dryzdfv0h5ke* (0%), and *9qn4n86pqg6g* (0%).\n",
    "\n",
    "To find locations where combo wind and solar farms could be built, I combined both of the matching criteria for wind and solar farms into one dataset from 2019. From here i found another 3 geohashes that would be suitable: *9xmfjt08b78u* (50.03mph wind, 0% cloud cover), *9xqjvg1hwpmu* (50.03mph, 0%), and *9wht5bzj7k0v* (50.04mph, 0%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8453f894",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read.load('hdfs://orion01:25001/2019/namanl_218_2019*.gz',\n",
    "                     format='csv',\n",
    "                     sep='\\t',\n",
    "                     inferSchema='true',\n",
    "                     header='true')\n",
    "\n",
    "df = df.withColumnRenamed(\"1_time\", \"time\").withColumnRenamed(\"2_lat\", \"lat\").withColumnRenamed(\"3_lon\", \"lon\")\n",
    "df = df.withColumn(\"geohash\", geohashEncodeUDF(df.lat, df.lon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18470f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.withColumn(\"wind_speed\", df.pressure_maximum_wind * 0.00256) # convert wind pressure to wind speed (mph)\n",
    "df = df.withColumn(\"wind_speed_gust_surface\", df.wind_speed_gust_surface * 2.23694) # convert gust speed to mph\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0f45d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.sort(\"total_cloud_cover_entire_atmosphere_single_layer\")\n",
    "\n",
    "# df = df.sort(\"albedo_surface\")\n",
    "\n",
    "df.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181df967",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"farms\")\n",
    "\n",
    "\n",
    "# wind.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2be6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "wind = spark.sql('SELECT * FROM farms WHERE 70 > wind_speed_gust_surface AND wind_speed_gust_surface > 50 \\\n",
    "AND 24 < lat AND lat < 50 AND -66 > lon AND lon > -124')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3084bc9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wind.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aafba0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hashes = wind.groupBy(\"geohash\")\\\n",
    "            .agg(F.avg(\"wind_speed_gust_surface\").alias(\"wind_speed\"), \\\n",
    "                F.avg(\"lat\").alias(\"lat\"), F.avg(\"lon\").alias(\"lon\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b7a62e",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb06c41",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wind_df = hashes.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196a9f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "wind_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91152e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "worldmap = gpd.read_file(gpd.datasets.get_path(\"naturalearth_lowres\"))\n",
    "worldmap[worldmap[\"name\"] == \"United States of America\"].plot(color=\"lightgrey\")\n",
    "\n",
    "# Plotting our Impact Energy data with a color map\n",
    "x = wind_df['lon']\n",
    "y = wind_df['lat']\n",
    "z = wind_df['wind_speed']\n",
    "plt.scatter(x, y, s=z/1000, c=z, cmap='Blues')\n",
    "\n",
    "plt.colorbar(label='Maximum Wind Gust Speed (mph)')\n",
    "\n",
    "plt.xlim([-128, -65])\n",
    "plt.ylim([24, 51])\n",
    "\n",
    "plt.xlabel(\"Longitude\")\n",
    "plt.ylabel(\"Latitude\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a26a06b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sun = spark.sql('SELECT * FROM farms WHERE total_cloud_cover_entire_atmosphere_single_layer < 15 AND \\\n",
    "        24 < lat AND lat < 50 AND -66 > lon AND lon > -124')\n",
    "\n",
    "sun = sun.withColumnRenamed(\"1_time\", \"time\").withColumnRenamed(\"2_lat\", \"lat\").withColumnRenamed(\"3_lon\", \"lon\")\n",
    "sun = sun.withColumn(\"geohash\", geohashEncodeUDF(df.lat, df.lon))\n",
    "\n",
    "sun.count()\n",
    "# 60 < albedo_surface AND \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c6719a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hashes = sun.groupBy(\"geohash\").agg(\\\n",
    "                                    F.avg(\"total_cloud_cover_entire_atmosphere_single_layer\").alias(\"cloud_cover\"), \\\n",
    "                                    F.avg(\"lat\").alias(\"lat\"), F.avg(\"lon\").alias(\"lon\"))\n",
    "\n",
    "hashes.limit(5).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7995baa9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sun_df = hashes.toPandas()\n",
    "\n",
    "sun_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea1a959",
   "metadata": {},
   "outputs": [],
   "source": [
    "worldmap = gpd.read_file(gpd.datasets.get_path(\"naturalearth_lowres\"))\n",
    "worldmap[worldmap[\"name\"] == \"United States of America\"].plot(color=\"lightgrey\")\n",
    "\n",
    "# Plotting our Impact Energy data with a color map\n",
    "x = sun_df['lon']\n",
    "y = sun_df['lat']\n",
    "z = sun_df['cloud_cover']\n",
    "plt.scatter(x, y, s=z/25, c=z, cmap='YlOrRd')\n",
    "\n",
    "plt.colorbar(label='Cloud Cover (%)')\n",
    "\n",
    "plt.xlim([-128, -65])\n",
    "plt.ylim([24, 51])\n",
    "\n",
    "plt.xlabel(\"Longitude\")\n",
    "plt.ylabel(\"Latitude\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1d1d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "farms = spark.sql('SELECT * FROM farms WHERE total_cloud_cover_entire_atmosphere_single_layer < 15 AND \\\n",
    "        70 > wind_speed_gust_surface AND wind_speed_gust_surface > 50 AND \\\n",
    "        24 < lat AND lat < 50 AND -66 > lon AND lon > -124')\n",
    "\n",
    "farms = farms.withColumnRenamed(\"1_time\", \"time\").withColumnRenamed(\"2_lat\", \"lat\").withColumnRenamed(\"3_lon\", \"lon\")\n",
    "farms = farms.withColumn(\"geohash\", geohashEncodeUDF(farms.lat, farms.lon))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a08e4db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "farms.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d852212",
   "metadata": {},
   "outputs": [],
   "source": [
    "farms_df = farms.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62e3c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "worldmap = gpd.read_file(gpd.datasets.get_path(\"naturalearth_lowres\"))\n",
    "worldmap[worldmap[\"name\"] == \"United States of America\"].plot(color=\"lightgrey\")\n",
    "\n",
    "# Plotting our Impact Energy data with a color map\n",
    "x = farms_df['lon']\n",
    "y = farms_df['lat']\n",
    "z = farms_df['total_cloud_cover_entire_atmosphere_single_layer']\n",
    "# z = farms_df['wind_speed_gust_surface']\n",
    "\n",
    "plt.scatter(x, y, s=z/25, c=z, cmap='Greens')\n",
    "\n",
    "plt.colorbar(label='Cloud Cover (%)')\n",
    "\n",
    "plt.xlim([-128, -65])\n",
    "plt.ylim([24, 51])\n",
    "\n",
    "plt.xlabel(\"Longitude\")\n",
    "plt.ylabel(\"Latitude\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d12609",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.scatter(farms_df.lon, farms_df.lat, c=\"Orange\", \\\n",
    "           s=farms_df.total_cloud_cover_entire_atmosphere_single_layer, label=\"Cloud Cover\", \\\n",
    "           alpha=0.3, edgecolors='none')\n",
    "\n",
    "ax.scatter(farms_df.lon, farms_df.lat, c=\"Blue\", \\\n",
    "           s=farms_df.wind_speed_gust_surface/40, label=\"Wind Speed\", \\\n",
    "           alpha=0.3, edgecolors='none')\n",
    "\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff82930b",
   "metadata": {},
   "outputs": [],
   "source": [
    "wind.createOrReplaceTempView(\"wind\")\n",
    "sun.createOrReplaceTempView(\"sun\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3d5900",
   "metadata": {},
   "outputs": [],
   "source": [
    "wind = wind.sort(desc(\"wind_speed_gust_surface\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d84d923",
   "metadata": {},
   "outputs": [],
   "source": [
    "wind.take(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ac924f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sun = sun.sort(\"total_cloud_cover_entire_atmosphere_single_layer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aaa69ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "sun.take(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c978e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "farms = farms.sort(\"total_cloud_cover_entire_atmosphere_single_layer\", \"wind_speed_gust_surface\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2ed28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "farms.take(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3523fb3d",
   "metadata": {},
   "source": [
    "#### Climate Change: Using two-character geohash aggregates across the entire NAM grid, determine temperature trends over the past 5 years. With the regions that have experienced an increase in temperatures, build a correlation matrix using Pearson’s correlation coefficient (PCC) to determine how the variables influence one another. Finally, determine whether or not the correlations are different based on the region (e.g., maybe temperature has increased in lockstep with humidity in one location but not another). Analyze your results: can you draw any conclusions from what you’ve found?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f688f336",
   "metadata": {},
   "source": [
    "#### Weather Station: Write a multi-threaded server (outside of Spark) that reads files from the dataset — one file per thread — and then streams them out on a socket for a Spark streaming context to consume (note: not ALL the files have to be opened at once! :-)). The program should produce records as fast as the network will support, i.e., faster than real time. \n",
    "\n",
    "####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a137a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For a new value newValue, compute the new count, new mean, the new M2.\n",
    "# mean accumulates the mean of the entire dataset\n",
    "# M2 aggregates the squared distance from the mean\n",
    "# count aggregates the number of samples seen so far\n",
    "def update(existingAggregate, newValue):\n",
    "    (count, mean, M2) = existingAggregate\n",
    "    count += 1\n",
    "    delta = newValue - mean\n",
    "    mean += delta / count\n",
    "    delta2 = newValue - mean\n",
    "    M2 += delta * delta2\n",
    "    return (count, mean, M2)\n",
    "\n",
    "# Retrieve the mean, variance and sample variance from an aggregate\n",
    "def finalize(existingAggregate):\n",
    "    (count, mean, M2) = existingAggregate\n",
    "    if count < 2:\n",
    "        return float(\"nan\")\n",
    "    else:\n",
    "        (mean, variance, sampleVariance) = (mean, M2 / count, M2 / (count - 1))\n",
    "        return (mean, variance, sampleVariance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9acc5f42",
   "metadata": {},
   "source": [
    "### Travel Startup: \n",
    "#### After graduating from USF, you found a startup that aims to provide personalized travel itineraries using big data analysis. Given your own personal preferences, build a plan for a year of travel across 5 locations. Or, in other words: pick 5 regions. What is the best time of year to visit them based on the dataset?\n",
    "* You have to convince your potential customers that your travel itinerary is better than something they could come up with themselves with a little Googling. You can use pictures, information about local points of interest, etc.\n",
    "\n",
    "Geohashes: *dk2* (The Bahamas), *9g3* (Mexico City), *c20* (Portland), *9xc* (Yellowstone), *9q9* (Clear Lake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6d53a56d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "51238"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.createOrReplaceTempView(\"locations\")\n",
    "\n",
    "lake = spark.sql(\"SELECT * from locations WHERE (geohash LIKE '9qb%')\")\n",
    "\n",
    "lake.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "16fd057b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "49368"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "portland = spark.sql(\"SELECT * from locations WHERE (geohash LIKE 'c20%')\")\n",
    "\n",
    "portland.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "41caf031",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "56474"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bahamas = spark.sql(\"SELECT * from locations WHERE (geohash LIKE 'dk2%')\")\n",
    "\n",
    "bahamas.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d3c1eefe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "58718"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mexico = spark.sql(\"SELECT * from locations WHERE (geohash LIKE '9g3%')\")\n",
    "\n",
    "mexico.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e7bcd7f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "50116"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yellowstone = spark.sql(\"SELECT * from locations WHERE (geohash LIKE '9xc%')\")\n",
    "\n",
    "yellowstone.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "38c84be0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(time=1554908400000, lat=44.25292921362976, lon=-110.96990375305577, albedo_surface=14.8, precipitable_water_entire_atmosphere_single_layer=5.976626, pressure_maximum_wind=23726.81, pressure_surface=76160.79, pressure_tropopause=26998.84, relative_humidity_zerodegc_isotherm=73.0, snow_depth_surface=0.04912, temperature_surface=274.11514, temperature_tropopause=216.91328, total_cloud_cover_entire_atmosphere_single_layer=100.0, total_precipitation_surface_3_hour_accumulation=0.0625, vegetation_surface=21.0, visibility_surface=24100.0, wilting_point_surface=0.066, wind_speed_gust_surface=13.020082, _c18=None, geohash='9xc5dzfpvzfm'),\n",
       " Row(time=1554908400000, lat=44.39119211262595, lon=-110.55727792459314, albedo_surface=15.3, precipitable_water_entire_atmosphere_single_layer=5.6766257, pressure_maximum_wind=22240.41, pressure_surface=74589.586, pressure_tropopause=26458.041, relative_humidity_zerodegc_isotherm=78.0, snow_depth_surface=0.04576, temperature_surface=273.30515, temperature_tropopause=216.31328, total_cloud_cover_entire_atmosphere_single_layer=100.0, total_precipitation_surface_3_hour_accumulation=0.0625, vegetation_surface=23.2, visibility_surface=24100.0, wilting_point_surface=0.066, wind_speed_gust_surface=12.920082, _c18=None, geohash='9xcks1ntktyx'),\n",
       " Row(time=1554908400000, lat=44.32368823093437, lon=-110.11135478077841, albedo_surface=24.1, precipitable_water_entire_atmosphere_single_layer=5.376626, pressure_maximum_wind=13188.411, pressure_surface=72551.19, pressure_tropopause=25745.24, relative_humidity_zerodegc_isotherm=85.0, snow_depth_surface=0.04776, temperature_surface=271.22516, temperature_tropopause=216.41328, total_cloud_cover_entire_atmosphere_single_layer=100.0, total_precipitation_surface_3_hour_accumulation=0.1875, vegetation_surface=22.0, visibility_surface=17100.0, wilting_point_surface=0.066, wind_speed_gust_surface=11.720082, _c18=None, geohash='9xcsnkgk5qqg'),\n",
       " Row(time=1554908400000, lat=43.94535879626563, lon=-110.91929953436738, albedo_surface=16.1, precipitable_water_entire_atmosphere_single_layer=6.2766256, pressure_maximum_wind=12283.611, pressure_surface=76057.586, pressure_tropopause=27142.041, relative_humidity_zerodegc_isotherm=81.0, snow_depth_surface=0.06512, temperature_surface=273.75516, temperature_tropopause=217.11328, total_cloud_cover_entire_atmosphere_single_layer=100.0, total_precipitation_surface_3_hour_accumulation=0.5625, vegetation_surface=22.4, visibility_surface=24100.0, wilting_point_surface=0.047, wind_speed_gust_surface=12.020082, _c18=None, geohash='9xc45bp02bxs'),\n",
       " Row(time=1554908400000, lat=44.902068050719635, lon=-110.64026491598511, albedo_surface=22.8, precipitable_water_entire_atmosphere_single_layer=6.076626, pressure_maximum_wind=26446.012, pressure_surface=75635.19, pressure_tropopause=26228.441, relative_humidity_zerodegc_isotherm=86.0, snow_depth_surface=0.0396, temperature_surface=273.27515, temperature_tropopause=215.81328, total_cloud_cover_entire_atmosphere_single_layer=97.0, total_precipitation_surface_3_hour_accumulation=0.125, vegetation_surface=22.9, visibility_surface=18800.0, wilting_point_surface=0.066, wind_speed_gust_surface=12.320082, _c18=None, geohash='9xcr6q4jwbnv'),\n",
       " Row(time=1554908400000, lat=43.98118903195163, lon=-110.49151716932178, albedo_surface=15.8, precipitable_water_entire_atmosphere_single_layer=5.876626, pressure_maximum_wind=12386.811, pressure_surface=74891.984, pressure_tropopause=26716.441, relative_humidity_zerodegc_isotherm=78.0, snow_depth_surface=0.0512, temperature_surface=273.17517, temperature_tropopause=217.11328, total_cloud_cover_entire_atmosphere_single_layer=100.0, total_precipitation_surface_3_hour_accumulation=0.0, vegetation_surface=22.4, visibility_surface=23100.0, wilting_point_surface=0.066, wind_speed_gust_surface=13.220082, _c18=None, geohash='9xc6jww8cpc7'),\n",
       " Row(time=1554908400000, lat=43.61623035580953, lon=-109.85781328818982, albedo_surface=24.3, precipitable_water_entire_atmosphere_single_layer=5.476626, pressure_maximum_wind=12057.211, pressure_surface=72439.19, pressure_tropopause=26477.24, relative_humidity_zerodegc_isotherm=73.0, snow_depth_surface=0.09424, temperature_surface=274.53516, temperature_tropopause=217.91328, total_cloud_cover_entire_atmosphere_single_layer=100.0, total_precipitation_surface_3_hour_accumulation=0.125, vegetation_surface=14.0, visibility_surface=24000.0, wilting_point_surface=0.069, wind_speed_gust_surface=10.320082, _c18=None, geohash='9xcbhh5fzqth'),\n",
       " Row(time=1554908400000, lat=43.924742113207124, lon=-109.90489830569132, albedo_surface=36.4, precipitable_water_entire_atmosphere_single_layer=4.6766257, pressure_maximum_wind=12514.011, pressure_surface=69824.79, pressure_tropopause=26097.24, relative_humidity_zerodegc_isotherm=86.0, snow_depth_surface=0.1148, temperature_surface=270.79517, temperature_tropopause=217.21329, total_cloud_cover_entire_atmosphere_single_layer=99.0, total_precipitation_surface_3_hour_accumulation=0.375, vegetation_surface=15.2, visibility_surface=10400.0, wilting_point_surface=0.066, wind_speed_gust_surface=11.520082, _c18=None, geohash='9xccgh38nm2h'),\n",
       " Row(time=1554908400000, lat=44.52842875105071, lon=-110.1434773447927, albedo_surface=16.8, precipitable_water_entire_atmosphere_single_layer=5.576626, pressure_maximum_wind=14914.811, pressure_surface=73226.39, pressure_tropopause=25574.84, relative_humidity_zerodegc_isotherm=83.0, snow_depth_surface=0.0468, temperature_surface=273.05515, temperature_tropopause=216.11328, total_cloud_cover_entire_atmosphere_single_layer=100.0, total_precipitation_surface_3_hour_accumulation=0.125, vegetation_surface=23.3, visibility_surface=20100.0, wilting_point_surface=0.066, wind_speed_gust_surface=11.120082, _c18=None, geohash='9xctmd5uyuwx'),\n",
       " Row(time=1554908400000, lat=44.55115901025401, lon=-109.85642164702875, albedo_surface=20.5, precipitable_water_entire_atmosphere_single_layer=5.476626, pressure_maximum_wind=16356.411, pressure_surface=72522.39, pressure_tropopause=25376.441, relative_humidity_zerodegc_isotherm=78.0, snow_depth_surface=0.05344, temperature_surface=273.88516, temperature_tropopause=216.01328, total_cloud_cover_entire_atmosphere_single_layer=100.0, total_precipitation_surface_3_hour_accumulation=0.125, vegetation_surface=23.2, visibility_surface=24000.0, wilting_point_surface=0.066, wind_speed_gust_surface=10.320082, _c18=None, geohash='9xcvknkcrcfz'),\n",
       " Row(time=1554908400000, lat=44.06000970305977, lon=-110.79342435709009, albedo_surface=15.6, precipitable_water_entire_atmosphere_single_layer=6.076626, pressure_maximum_wind=12426.011, pressure_surface=75827.984, pressure_tropopause=26999.64, relative_humidity_zerodegc_isotherm=74.0, snow_depth_surface=0.05304, temperature_surface=274.01517, temperature_tropopause=217.11328, total_cloud_cover_entire_atmosphere_single_layer=100.0, total_precipitation_surface_3_hour_accumulation=0.0625, vegetation_surface=23.4, visibility_surface=24100.0, wilting_point_surface=0.047, wind_speed_gust_surface=12.320082, _c18=None, geohash='9xc4wufsnj55'),\n",
       " Row(time=1554908400000, lat=43.96935447433411, lon=-110.63414662119555, albedo_surface=15.8, precipitable_water_entire_atmosphere_single_layer=5.976626, pressure_maximum_wind=12338.811, pressure_surface=75189.586, pressure_tropopause=26895.64, relative_humidity_zerodegc_isotherm=78.0, snow_depth_surface=0.0548, temperature_surface=273.08514, temperature_tropopause=217.21329, total_cloud_cover_entire_atmosphere_single_layer=100.0, total_precipitation_surface_3_hour_accumulation=0.0625, vegetation_surface=22.4, visibility_surface=24100.0, wilting_point_surface=0.066, wind_speed_gust_surface=12.720082, _c18=None, geohash='9xc64kqsj99p'),\n",
       " Row(time=1554908400000, lat=44.300538127999445, lon=-110.39767599232013, albedo_surface=23.6, precipitable_water_entire_atmosphere_single_layer=5.576626, pressure_maximum_wind=13019.611, pressure_surface=74147.984, pressure_tropopause=26169.24, relative_humidity_zerodegc_isotherm=84.0, snow_depth_surface=0.04992, temperature_surface=271.93515, temperature_tropopause=216.31328, total_cloud_cover_entire_atmosphere_single_layer=100.0, total_precipitation_surface_3_hour_accumulation=0.0625, vegetation_surface=23.9, visibility_surface=22800.0, wilting_point_surface=0.066, wind_speed_gust_surface=13.120082, _c18=None, geohash='9xckpbdv7dy7'),\n",
       " Row(time=1554908400000, lat=44.67409812429997, lon=-110.8942742036804, albedo_surface=14.9, precipitable_water_entire_atmosphere_single_layer=5.976626, pressure_maximum_wind=26686.012, pressure_surface=76027.984, pressure_tropopause=26729.24, relative_humidity_zerodegc_isotherm=77.0, snow_depth_surface=0.0388, temperature_surface=274.92517, temperature_tropopause=216.51328, total_cloud_cover_entire_atmosphere_single_layer=96.0, total_precipitation_surface_3_hour_accumulation=0.0, vegetation_surface=22.8, visibility_surface=24100.0, wilting_point_surface=0.066, wind_speed_gust_surface=12.420082, _c18=None, geohash='9xcnhs9m2p7z'),\n",
       " Row(time=1554908400000, lat=44.87821232628161, lon=-110.9281764367617, albedo_surface=20.6, precipitable_water_entire_atmosphere_single_layer=5.6766257, pressure_maximum_wind=26766.012, pressure_surface=75243.984, pressure_tropopause=26388.441, relative_humidity_zerodegc_isotherm=83.0, snow_depth_surface=0.0432, temperature_surface=272.88516, temperature_tropopause=216.11328, total_cloud_cover_entire_atmosphere_single_layer=84.0, total_precipitation_surface_3_hour_accumulation=0.0625, vegetation_surface=20.8, visibility_surface=21200.0, wilting_point_surface=0.066, wind_speed_gust_surface=13.020082, _c18=None, geohash='9xcp7cbdd1hs'),\n",
       " Row(time=1554908400000, lat=44.868959903259025, lon=-109.75992689448168, albedo_surface=23.9, precipitable_water_entire_atmosphere_single_layer=5.1766257, pressure_maximum_wind=26497.213, pressure_surface=72530.39, pressure_tropopause=25134.041, relative_humidity_zerodegc_isotherm=72.0, snow_depth_surface=0.05992, temperature_surface=273.74515, temperature_tropopause=215.41328, total_cloud_cover_entire_atmosphere_single_layer=96.0, total_precipitation_surface_3_hour_accumulation=0.0, vegetation_surface=23.9, visibility_surface=23900.0, wilting_point_surface=0.066, wind_speed_gust_surface=10.120082, _c18=None, geohash='9xczq25k8k6e'),\n",
       " Row(time=1554908400000, lat=44.03578707151398, lon=-111.07880414930705, albedo_surface=14.7, precipitable_water_entire_atmosphere_single_layer=7.076626, pressure_maximum_wind=12353.211, pressure_surface=78987.19, pressure_tropopause=27146.84, relative_humidity_zerodegc_isotherm=76.0, snow_depth_surface=0.0408, temperature_surface=275.35516, temperature_tropopause=217.11328, total_cloud_cover_entire_atmosphere_single_layer=100.0, total_precipitation_surface_3_hour_accumulation=0.125, vegetation_surface=19.7, visibility_surface=24100.0, wilting_point_surface=0.047, wind_speed_gust_surface=11.420082, _c18=None, geohash='9xc4826zh38m'),\n",
       " Row(time=1554908400000, lat=44.607513762564686, lon=-110.44680895688782, albedo_surface=16.0, precipitable_water_entire_atmosphere_single_layer=5.576626, pressure_maximum_wind=26308.412, pressure_surface=74335.984, pressure_tropopause=26100.441, relative_humidity_zerodegc_isotherm=81.0, snow_depth_surface=0.04392, temperature_surface=273.49515, temperature_tropopause=216.01328, total_cloud_cover_entire_atmosphere_single_layer=100.0, total_precipitation_surface_3_hour_accumulation=0.0625, vegetation_surface=23.6, visibility_surface=24100.0, wilting_point_surface=0.066, wind_speed_gust_surface=11.820082, _c18=None, geohash='9xcmy8x1dg60'),\n",
       " Row(time=1554908400000, lat=43.992914675399064, lon=-110.34885326704475, albedo_surface=16.2, precipitable_water_entire_atmosphere_single_layer=5.6766257, pressure_maximum_wind=12446.811, pressure_surface=74055.19, pressure_tropopause=26481.24, relative_humidity_zerodegc_isotherm=81.0, snow_depth_surface=0.05264, temperature_surface=272.55515, temperature_tropopause=216.91328, total_cloud_cover_entire_atmosphere_single_layer=100.0, total_precipitation_surface_3_hour_accumulation=0.0625, vegetation_surface=21.5, visibility_surface=20100.0, wilting_point_surface=0.066, wind_speed_gust_surface=13.420082, _c18=None, geohash='9xcd2bwmm3eq'),\n",
       " Row(time=1554908400000, lat=44.59576227864569, lon=-110.5903673513939, albedo_surface=15.4, precipitable_water_entire_atmosphere_single_layer=5.6766257, pressure_maximum_wind=26361.213, pressure_surface=74702.39, pressure_tropopause=26470.041, relative_humidity_zerodegc_isotherm=79.0, snow_depth_surface=0.04376, temperature_surface=273.77515, temperature_tropopause=216.11328, total_cloud_cover_entire_atmosphere_single_layer=100.0, total_precipitation_surface_3_hour_accumulation=0.0625, vegetation_surface=23.6, visibility_surface=24100.0, wilting_point_surface=0.066, wind_speed_gust_surface=12.420082, _c18=None, geohash='9xcmeqqt1stk')]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yellowstone.take(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe69eb4",
   "metadata": {},
   "source": [
    "### Clear Lake\n",
    "\n",
    "Ideal Temperature: 65-75 F\n",
    "\n",
    "Wind Speed: 0-5mph\n",
    "\n",
    "Cloud Cover: 40-70%\n",
    "\n",
    "**Ideal time: Jun-Aug**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d3a9e5f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "jan = spark.read.load('hdfs://orion01:25001/2019/namanl_218_201901*.gz',\n",
    "                     format='csv',\n",
    "                     sep='\\t',\n",
    "                     inferSchema='true',\n",
    "                     header='true')\n",
    "\n",
    "feb = spark.read.load('hdfs://orion01:25001/2019/namanl_218_201902*.gz',\n",
    "                     format='csv',\n",
    "                     sep='\\t',\n",
    "                     inferSchema='true',\n",
    "                     header='true')\n",
    "\n",
    "mar = spark.read.load('hdfs://orion01:25001/2019/namanl_218_201903*.gz',\n",
    "                     format='csv',\n",
    "                     sep='\\t',\n",
    "                     inferSchema='true',\n",
    "                     header='true')\n",
    "\n",
    "apr = spark.read.load('hdfs://orion01:25001/2019/namanl_218_201904*.gz',\n",
    "                     format='csv',\n",
    "                     sep='\\t',\n",
    "                     inferSchema='true',\n",
    "                     header='true')\n",
    "\n",
    "may = spark.read.load('hdfs://orion01:25001/2019/namanl_218_201905*.gz',\n",
    "                     format='csv',\n",
    "                     sep='\\t',\n",
    "                     inferSchema='true',\n",
    "                     header='true')\n",
    "\n",
    "jun = spark.read.load('hdfs://orion01:25001/2019/namanl_218_201906*.gz',\n",
    "                     format='csv',\n",
    "                     sep='\\t',\n",
    "                     inferSchema='true',\n",
    "                     header='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2fdc9b30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "jul = spark.read.load('hdfs://orion01:25001/2019/namanl_218_201907*.gz',\n",
    "                     format='csv',\n",
    "                     sep='\\t',\n",
    "                     inferSchema='true',\n",
    "                     header='true')\n",
    "\n",
    "aug = spark.read.load('hdfs://orion01:25001/2019/namanl_218_201908*.gz',\n",
    "                     format='csv',\n",
    "                     sep='\\t',\n",
    "                     inferSchema='true',\n",
    "                     header='true')\n",
    "\n",
    "sep = spark.read.load('hdfs://orion01:25001/2019/namanl_218_201909*.gz',\n",
    "                     format='csv',\n",
    "                     sep='\\t',\n",
    "                     inferSchema='true',\n",
    "                     header='true')\n",
    "\n",
    "octo = spark.read.load('hdfs://orion01:25001/2019/namanl_218_201910*.gz',\n",
    "                     format='csv',\n",
    "                     sep='\\t',\n",
    "                     inferSchema='true',\n",
    "                     header='true')\n",
    "\n",
    "nov = spark.read.load('hdfs://orion01:25001/2019/namanl_218_201911*.gz',\n",
    "                     format='csv',\n",
    "                     sep='\\t',\n",
    "                     inferSchema='true',\n",
    "                     header='true')\n",
    "\n",
    "dec = spark.read.load('hdfs://orion01:25001/2019/namanl_218_201912*.gz',\n",
    "                     format='csv',\n",
    "                     sep='\\t',\n",
    "                     inferSchema='true',\n",
    "                     header='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e696f0cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(time=1546722000000, lat=58.424226538128224, lon=-88.11817117586963, albedo_surface=65.0, precipitable_water_entire_atmosphere_single_layer=1.4045608, pressure_maximum_wind=11128.6875, pressure_surface=101525.72, pressure_tropopause=33332.16, relative_humidity_zerodegc_isotherm=74.0, snow_depth_surface=0.05, temperature_surface=-22.15636599999999, temperature_tropopause=218.16837, total_cloud_cover_entire_atmosphere_single_layer=0.0, total_precipitation_surface_3_hour_accumulation=0.0, vegetation_surface=0.0, visibility_surface=24100.0, wilting_point_surface=0.0, wind_speed_gust_surface=19.32594917852, _c18=None, geohash='f43k6gf3cc1q')]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jan = jan.withColumnRenamed(\"1_time\", \"time\").withColumnRenamed(\"2_lat\", \"lat\").withColumnRenamed(\"3_lon\", \"lon\")\n",
    "jan = jan.withColumn(\"geohash\", geohashEncodeUDF(jan.lat, jan.lon)).withColumn(\"temperature_surface\",\\\n",
    "                                                                               k2f(jan.temperature_surface))\n",
    "jan = jan.withColumn(\"wind_speed_gust_surface\", jan.wind_speed_gust_surface * 2.23694) # convert gust speed to mph\n",
    "\n",
    "feb = feb.withColumnRenamed(\"1_time\", \"time\").withColumnRenamed(\"2_lat\", \"lat\").withColumnRenamed(\"3_lon\", \"lon\")\n",
    "feb = feb.withColumn(\"geohash\", geohashEncodeUDF(feb.lat, feb.lon)).withColumn(\"temperature_surface\",\\\n",
    "                                                                               k2f(feb.temperature_surface))\n",
    "feb = feb.withColumn(\"wind_speed_gust_surface\", feb.wind_speed_gust_surface * 2.23694) # convert gust speed to mph\n",
    "\n",
    "mar = mar.withColumnRenamed(\"1_time\", \"time\").withColumnRenamed(\"2_lat\", \"lat\").withColumnRenamed(\"3_lon\", \"lon\")\n",
    "mar = mar.withColumn(\"geohash\", geohashEncodeUDF(mar.lat, mar.lon)).withColumn(\"temperature_surface\",\\\n",
    "                                                                               k2f(mar.temperature_surface))\n",
    "mar = mar.withColumn(\"wind_speed_gust_surface\", mar.wind_speed_gust_surface * 2.23694) # convert gust speed to mph\n",
    "\n",
    "apr = apr.withColumnRenamed(\"1_time\", \"time\").withColumnRenamed(\"2_lat\", \"lat\").withColumnRenamed(\"3_lon\", \"lon\")\n",
    "apr = apr.withColumn(\"geohash\", geohashEncodeUDF(apr.lat, apr.lon)).withColumn(\"temperature_surface\",\\\n",
    "                                                                               k2f(apr.temperature_surface))\n",
    "apr = apr.withColumn(\"wind_speed_gust_surface\", apr.wind_speed_gust_surface * 2.23694) # convert gust speed to mph\n",
    "\n",
    "may = may.withColumnRenamed(\"1_time\", \"time\").withColumnRenamed(\"2_lat\", \"lat\").withColumnRenamed(\"3_lon\", \"lon\")\n",
    "may = may.withColumn(\"geohash\", geohashEncodeUDF(may.lat, may.lon)).withColumn(\"temperature_surface\",\\\n",
    "                                                                               k2f(may.temperature_surface))\n",
    "may = may.withColumn(\"wind_speed_gust_surface\", may.wind_speed_gust_surface * 2.23694) # convert gust speed to mph\n",
    "\n",
    "jun = jun.withColumnRenamed(\"1_time\", \"time\").withColumnRenamed(\"2_lat\", \"lat\").withColumnRenamed(\"3_lon\", \"lon\")\n",
    "jun = jun.withColumn(\"geohash\", geohashEncodeUDF(jun.lat, jun.lon)).withColumn(\"temperature_surface\",\\\n",
    "                                                                               k2f(jun.temperature_surface))\n",
    "jun = jun.withColumn(\"wind_speed_gust_surface\", jun.wind_speed_gust_surface * 2.23694) # convert gust speed to mph\n",
    "\n",
    "jul = jul.withColumnRenamed(\"1_time\", \"time\").withColumnRenamed(\"2_lat\", \"lat\").withColumnRenamed(\"3_lon\", \"lon\")\n",
    "jul = jul.withColumn(\"geohash\", geohashEncodeUDF(jul.lat, jul.lon)).withColumn(\"temperature_surface\",\\\n",
    "                                                                               k2f(jul.temperature_surface))\n",
    "jul = jul.withColumn(\"wind_speed_gust_surface\", jul.wind_speed_gust_surface * 2.23694) # convert gust speed to mph\n",
    "\n",
    "aug = aug.withColumnRenamed(\"1_time\", \"time\").withColumnRenamed(\"2_lat\", \"lat\").withColumnRenamed(\"3_lon\", \"lon\")\n",
    "aug = aug.withColumn(\"geohash\", geohashEncodeUDF(aug.lat, aug.lon)).withColumn(\"temperature_surface\",\\\n",
    "                                                                               k2f(aug.temperature_surface))\n",
    "aug = aug.withColumn(\"wind_speed_gust_surface\", aug.wind_speed_gust_surface * 2.23694) # convert gust speed to mph\n",
    "\n",
    "sep = sep.withColumnRenamed(\"1_time\", \"time\").withColumnRenamed(\"2_lat\", \"lat\").withColumnRenamed(\"3_lon\", \"lon\")\n",
    "sep = sep.withColumn(\"geohash\", geohashEncodeUDF(sep.lat, sep.lon)).withColumn(\"temperature_surface\",\\\n",
    "                                                                               k2f(sep.temperature_surface))\n",
    "sep = sep.withColumn(\"wind_speed_gust_surface\", sep.wind_speed_gust_surface * 2.23694) # convert gust speed to mph\n",
    "\n",
    "octo = octo.withColumnRenamed(\"1_time\", \"time\").withColumnRenamed(\"2_lat\", \"lat\").withColumnRenamed(\"3_lon\", \"lon\")\n",
    "octo = octo.withColumn(\"geohash\", geohashEncodeUDF(octo.lat, octo.lon)).withColumn(\"temperature_surface\",\\\n",
    "                                                                               k2f(octo.temperature_surface))\n",
    "octo = octo.withColumn(\"wind_speed_gust_surface\", octo.wind_speed_gust_surface * 2.23694) # convert gust speed to mph\n",
    "\n",
    "nov = nov.withColumnRenamed(\"1_time\", \"time\").withColumnRenamed(\"2_lat\", \"lat\").withColumnRenamed(\"3_lon\", \"lon\")\n",
    "nov = nov.withColumn(\"geohash\", geohashEncodeUDF(nov.lat, nov.lon)).withColumn(\"temperature_surface\",\\\n",
    "                                                                               k2f(nov.temperature_surface))\n",
    "nov = nov.withColumn(\"wind_speed_gust_surface\", nov.wind_speed_gust_surface * 2.23694) # convert gust speed to mph\n",
    "\n",
    "dec = dec.withColumnRenamed(\"1_time\", \"time\").withColumnRenamed(\"2_lat\", \"lat\").withColumnRenamed(\"3_lon\", \"lon\")\n",
    "dec = dec.withColumn(\"geohash\", geohashEncodeUDF(dec.lat, dec.lon)).withColumn(\"temperature_surface\",\\\n",
    "                                                                               k2f(dec.temperature_surface))\n",
    "dec = dec.withColumn(\"wind_speed_gust_surface\", dec.wind_speed_gust_surface * 2.23694) # convert gust speed to mph\n",
    "    \n",
    "jan.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e51838bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "jan.createOrReplaceTempView(\"jan\")\n",
    "feb.createOrReplaceTempView(\"feb\")\n",
    "mar.createOrReplaceTempView(\"mar\")\n",
    "apr.createOrReplaceTempView(\"apr\")\n",
    "may.createOrReplaceTempView(\"may\")\n",
    "jun.createOrReplaceTempView(\"jun\")\n",
    "jul.createOrReplaceTempView(\"jul\")\n",
    "aug.createOrReplaceTempView(\"aug\")\n",
    "sep.createOrReplaceTempView(\"sep\")\n",
    "octo.createOrReplaceTempView(\"oct\")\n",
    "nov.createOrReplaceTempView(\"nov\")\n",
    "dec.createOrReplaceTempView(\"dec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b960e6",
   "metadata": {},
   "source": [
    "### Clear Lake: Water Sports\n",
    "\n",
    "Ideal Temperature: 65-75 F\n",
    "\n",
    "Wind Speed: 0-5mph\n",
    "\n",
    "Cloud Cover: 0-50%\n",
    "\n",
    "**Ideal Time: Apr-Jul**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "e079329a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "212"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lake = spark.sql(\"SELECT * from jan WHERE (geohash LIKE '9qb%')\\\n",
    "                    AND 65 < temperature_surface AND temperature_surface < 75\\\n",
    "                    AND 5 >= wind_speed_gust_surface \\\n",
    "                    AND 50 > total_cloud_cover_entire_atmosphere_single_layer\")\n",
    "\n",
    "lake.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "d1000ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lake = spark.sql(\"SELECT * from feb WHERE (geohash LIKE '9qb%')\\\n",
    "                    AND 65 < temperature_surface AND temperature_surface < 75\\\n",
    "                    AND 5 >= wind_speed_gust_surface \\\n",
    "                    AND 50 > total_cloud_cover_entire_atmosphere_single_layer\")\n",
    "\n",
    "lake.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "8e031b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lake = spark.sql(\"SELECT * from mar WHERE (geohash LIKE '9qb%')\\\n",
    "                    AND 65 < temperature_surface AND temperature_surface < 75\\\n",
    "                    AND 5 >= wind_speed_gust_surface \\\n",
    "                    AND 50 > total_cloud_cover_entire_atmosphere_single_layer\")\n",
    "\n",
    "lake.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "ab433657",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lake = spark.sql(\"SELECT * from may WHERE (geohash LIKE '9qb%')\\\n",
    "                    AND 65 < temperature_surface AND temperature_surface < 75\\\n",
    "                    AND 5 >= wind_speed_gust_surface \\\n",
    "                    AND 50 > total_cloud_cover_entire_atmosphere_single_layer\")\n",
    "\n",
    "lake.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "4b220a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "778"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lake = spark.sql(\"SELECT * from jun WHERE (geohash LIKE '9qb%')\\\n",
    "                    AND 65 < temperature_surface AND temperature_surface < 75\\\n",
    "                    AND 5 >= wind_speed_gust_surface \\\n",
    "                    AND 50 > total_cloud_cover_entire_atmosphere_single_layer\")\n",
    "\n",
    "lake.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "2b2c4310",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "840"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lake = spark.sql(\"SELECT * from jul WHERE (geohash LIKE '9qb%')\\\n",
    "                    AND 65 < temperature_surface AND temperature_surface < 75\\\n",
    "                    AND 5 >= wind_speed_gust_surface \\\n",
    "                    AND 50 > total_cloud_cover_entire_atmosphere_single_layer\")\n",
    "\n",
    "lake.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "6acdd2d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "986"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lake = spark.sql(\"SELECT * from aug WHERE (geohash LIKE '9qb%')\\\n",
    "                    AND 65 < temperature_surface AND temperature_surface < 75\\\n",
    "                    AND 5 >= wind_speed_gust_surface \\\n",
    "                    AND 50 > total_cloud_cover_entire_atmosphere_single_layer\")\n",
    "\n",
    "lake.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "fc2d9cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "328"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lake = spark.sql(\"SELECT * from sep WHERE (geohash LIKE '9qb%')\\\n",
    "                    AND 65 < temperature_surface AND temperature_surface < 75\\\n",
    "                    AND 5 >= wind_speed_gust_surface \\\n",
    "                    AND 50 > total_cloud_cover_entire_atmosphere_single_layer\")\n",
    "\n",
    "lake.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "0fcdfd1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lake = spark.sql(\"SELECT * from oct WHERE (geohash LIKE '9qb%')\\\n",
    "                    AND 65 < temperature_surface AND temperature_surface < 75\\\n",
    "                    AND 5 >= wind_speed_gust_surface \\\n",
    "                    AND 50 > total_cloud_cover_entire_atmosphere_single_layer\")\n",
    "\n",
    "lake.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "ff17406b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lake = spark.sql(\"SELECT * from nov WHERE (geohash LIKE '9qb%')\\\n",
    "                    AND 65 < temperature_surface AND temperature_surface < 75\\\n",
    "                    AND 5 >= wind_speed_gust_surface \\\n",
    "                    AND 50 > total_cloud_cover_entire_atmosphere_single_layer\")\n",
    "\n",
    "lake.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2df6e14d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lake = spark.sql(\"SELECT * from nov WHERE (geohash LIKE '9qb%')\\\n",
    "                    AND 65 < temperature_surface AND temperature_surface < 75\\\n",
    "                    AND 5 >= wind_speed_gust_surface \\\n",
    "                    AND 40 < total_cloud_cover_entire_atmosphere_single_layer AND total_cloud_cover_entire_atmosphere_single_layer < 70\")\n",
    "\n",
    "lake.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "6ef22d5f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lake = spark.sql(\"SELECT * from dec WHERE (geohash LIKE '9qb%')\\\n",
    "                    AND 65 < temperature_surface AND temperature_surface < 75\\\n",
    "                    AND 5 >= wind_speed_gust_surface \\\n",
    "                    AND 50 > total_cloud_cover_entire_atmosphere_single_layer\")\n",
    "\n",
    "lake.count()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53cb9196",
   "metadata": {},
   "source": [
    "### Bahamas: Sunbathing\n",
    "\n",
    "Ideal Temperature: 75+ F\n",
    "\n",
    "Wind Speed: 0-5mph\n",
    "\n",
    "Cloud Cover: 0-10%\n",
    "\n",
    "**Ideal Time: Jun-Aug**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "a8ac27d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bahamas = spark.sql(\"SELECT * from jan WHERE (geohash LIKE 'dk2%')\\\n",
    "                    AND 75 < temperature_surface \\\n",
    "                    AND 5 >= wind_speed_gust_surface \\\n",
    "                    AND 0 < total_cloud_cover_entire_atmosphere_single_layer AND total_cloud_cover_entire_atmosphere_single_layer < 10\")\n",
    "\n",
    "bahamas.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "55cd369d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bahamas = spark.sql(\"SELECT * from feb WHERE (geohash LIKE 'dk2%')\\\n",
    "                    AND 75 < temperature_surface \\\n",
    "                    AND 5 >= wind_speed_gust_surface \\\n",
    "                    AND 0 < total_cloud_cover_entire_atmosphere_single_layer AND total_cloud_cover_entire_atmosphere_single_layer < 10\")\n",
    "\n",
    "bahamas.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "619bb915",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bahamas = spark.sql(\"SELECT * from mar WHERE (geohash LIKE 'dk2%')\\\n",
    "                    AND 75 < temperature_surface \\\n",
    "                    AND 5 >= wind_speed_gust_surface \\\n",
    "                    AND 0 < total_cloud_cover_entire_atmosphere_single_layer AND total_cloud_cover_entire_atmosphere_single_layer < 10\")\n",
    "\n",
    "bahamas.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "9cd438f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bahamas = spark.sql(\"SELECT * from apr WHERE (geohash LIKE 'dk2%')\\\n",
    "                    AND 75 < temperature_surface \\\n",
    "                    AND 5 >= wind_speed_gust_surface \\\n",
    "                    AND 0 < total_cloud_cover_entire_atmosphere_single_layer AND total_cloud_cover_entire_atmosphere_single_layer < 10\")\n",
    "\n",
    "bahamas.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "34bf20f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bahamas = spark.sql(\"SELECT * from may WHERE (geohash LIKE 'dk2%')\\\n",
    "                    AND 75 < temperature_surface \\\n",
    "                    AND 5 >= wind_speed_gust_surface \\\n",
    "                    AND 0 < total_cloud_cover_entire_atmosphere_single_layer AND total_cloud_cover_entire_atmosphere_single_layer < 10\")\n",
    "\n",
    "bahamas.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "66329824",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "95"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bahamas = spark.sql(\"SELECT * from jun WHERE (geohash LIKE 'dk2%')\\\n",
    "                    AND 75 < temperature_surface \\\n",
    "                    AND 5 >= wind_speed_gust_surface \\\n",
    "                    AND 0 < total_cloud_cover_entire_atmosphere_single_layer AND total_cloud_cover_entire_atmosphere_single_layer < 10\")\n",
    "\n",
    "bahamas.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "ea9fdad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "84"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bahamas = spark.sql(\"SELECT * from jul WHERE (geohash LIKE 'dk2%')\\\n",
    "                    AND 75 < temperature_surface \\\n",
    "                    AND 5 >= wind_speed_gust_surface \\\n",
    "                    AND 0 < total_cloud_cover_entire_atmosphere_single_layer AND total_cloud_cover_entire_atmosphere_single_layer < 10\")\n",
    "\n",
    "bahamas.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "d960ffb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "66"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bahamas = spark.sql(\"SELECT * from aug WHERE (geohash LIKE 'dk2%')\\\n",
    "                    AND 75 < temperature_surface \\\n",
    "                    AND 5 >= wind_speed_gust_surface \\\n",
    "                    AND 0 < total_cloud_cover_entire_atmosphere_single_layer AND total_cloud_cover_entire_atmosphere_single_layer < 10\")\n",
    "\n",
    "bahamas.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "4dc4b6a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bahamas = spark.sql(\"SELECT * from sep WHERE (geohash LIKE 'dk2%')\\\n",
    "                    AND 75 < temperature_surface \\\n",
    "                    AND 5 >= wind_speed_gust_surface \\\n",
    "                    AND 0 < total_cloud_cover_entire_atmosphere_single_layer AND total_cloud_cover_entire_atmosphere_single_layer < 10\")\n",
    "\n",
    "bahamas.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "9dd1209a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bahamas = spark.sql(\"SELECT * from oct WHERE (geohash LIKE 'dk2%')\\\n",
    "                    AND 75 < temperature_surface \\\n",
    "                    AND 5 >= wind_speed_gust_surface \\\n",
    "                    AND 0 < total_cloud_cover_entire_atmosphere_single_layer AND total_cloud_cover_entire_atmosphere_single_layer < 10\")\n",
    "\n",
    "bahamas.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "9aafaf4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bahamas = spark.sql(\"SELECT * from nov WHERE (geohash LIKE 'dk2%')\\\n",
    "                    AND 75 < temperature_surface \\\n",
    "                    AND 5 >= wind_speed_gust_surface \\\n",
    "                    AND 0 < total_cloud_cover_entire_atmosphere_single_layer AND total_cloud_cover_entire_atmosphere_single_layer < 10\")\n",
    "\n",
    "bahamas.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "f166e0c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bahamas = spark.sql(\"SELECT * from dec WHERE (geohash LIKE 'dk2%')\\\n",
    "                    AND 75 < temperature_surface \\\n",
    "                    AND 5 >= wind_speed_gust_surface \\\n",
    "                    AND 0 < total_cloud_cover_entire_atmosphere_single_layer AND total_cloud_cover_entire_atmosphere_single_layer < 10\")\n",
    "\n",
    "bahamas.count()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29e5b33",
   "metadata": {},
   "source": [
    "### Yellowstone National Park: Rock Climbing\n",
    "\n",
    "Ideal Temperature: 55-75 F\n",
    "\n",
    "Wind Speed: 0-5mph\n",
    "\n",
    "Cloud Cover: 50-100%\n",
    "\n",
    "**Ideal Time: Jul-Aug**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "dee14840",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yellowstone = spark.sql(\"SELECT * from jan WHERE (geohash LIKE '9xc%')\\\n",
    "                    AND 55 < temperature_surface AND temperature_surface < 75\\\n",
    "                    AND 5 >= wind_speed_gust_surface \\\n",
    "                    AND 50 < total_cloud_cover_entire_atmosphere_single_layer\")\n",
    "\n",
    "yellowstone.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "8d39ebdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yellowstone = spark.sql(\"SELECT * from feb WHERE (geohash LIKE '9xc%')\\\n",
    "                    AND 55 < temperature_surface AND temperature_surface < 75\\\n",
    "                    AND 5 >= wind_speed_gust_surface \\\n",
    "                    AND 50 < total_cloud_cover_entire_atmosphere_single_layer\")\n",
    "\n",
    "yellowstone.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "06c557c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yellowstone = spark.sql(\"SELECT * from mar WHERE (geohash LIKE '9xc%')\\\n",
    "                    AND 55 < temperature_surface AND temperature_surface < 75\\\n",
    "                    AND 5 >= wind_speed_gust_surface \\\n",
    "                    AND 50 < total_cloud_cover_entire_atmosphere_single_layer\")\n",
    "\n",
    "yellowstone.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "7825fda2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yellowstone = spark.sql(\"SELECT * from apr WHERE (geohash LIKE '9xc%')\\\n",
    "                    AND 55 < temperature_surface AND temperature_surface < 75\\\n",
    "                    AND 5 >= wind_speed_gust_surface \\\n",
    "                    AND 50 < total_cloud_cover_entire_atmosphere_single_layer\")\n",
    "\n",
    "yellowstone.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "b46d8aa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yellowstone = spark.sql(\"SELECT * from may WHERE (geohash LIKE '9xc%')\\\n",
    "                    AND 55 < temperature_surface AND temperature_surface < 75\\\n",
    "                    AND 5 >= wind_speed_gust_surface \\\n",
    "                    AND 50 < total_cloud_cover_entire_atmosphere_single_layer\")\n",
    "\n",
    "yellowstone.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "8e533ff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yellowstone = spark.sql(\"SELECT * from jun WHERE (geohash LIKE '9xc%')\\\n",
    "                    AND 55 < temperature_surface AND temperature_surface < 75\\\n",
    "                    AND 5 >= wind_speed_gust_surface \\\n",
    "                    AND 50 < total_cloud_cover_entire_atmosphere_single_layer\")\n",
    "\n",
    "yellowstone.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "c7d60c48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "115"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yellowstone = spark.sql(\"SELECT * from jul WHERE (geohash LIKE '9xc%')\\\n",
    "                    AND 55 < temperature_surface AND temperature_surface < 75\\\n",
    "                    AND 5 >= wind_speed_gust_surface \\\n",
    "                    AND 50 < total_cloud_cover_entire_atmosphere_single_layer\")\n",
    "\n",
    "yellowstone.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "fb150828",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "81"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yellowstone = spark.sql(\"SELECT * from aug WHERE (geohash LIKE '9xc%')\\\n",
    "                    AND 55 < temperature_surface AND temperature_surface < 75\\\n",
    "                    AND 5 >= wind_speed_gust_surface \\\n",
    "                    AND 50 < total_cloud_cover_entire_atmosphere_single_layer\")\n",
    "\n",
    "yellowstone.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "575e213d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yellowstone = spark.sql(\"SELECT * from sep WHERE (geohash LIKE '9xc%')\\\n",
    "                    AND 55 < temperature_surface AND temperature_surface < 75\\\n",
    "                    AND 5 >= wind_speed_gust_surface \\\n",
    "                    AND 50 < total_cloud_cover_entire_atmosphere_single_layer\")\n",
    "\n",
    "yellowstone.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "984eb217",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yellowstone = spark.sql(\"SELECT * from oct WHERE (geohash LIKE '9xc%')\\\n",
    "                    AND 55 < temperature_surface AND temperature_surface < 75\\\n",
    "                    AND 5 >= wind_speed_gust_surface \\\n",
    "                    AND 50 < total_cloud_cover_entire_atmosphere_single_layer\")\n",
    "\n",
    "yellowstone.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "83ceba14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yellowstone = spark.sql(\"SELECT * from nov WHERE (geohash LIKE '9xc%')\\\n",
    "                    AND 55 < temperature_surface AND temperature_surface < 75\\\n",
    "                    AND 5 >= wind_speed_gust_surface \\\n",
    "                    AND 50 < total_cloud_cover_entire_atmosphere_single_layer\")\n",
    "\n",
    "yellowstone.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "4b844c5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yellowstone = spark.sql(\"SELECT * from dec WHERE (geohash LIKE '9xc%')\\\n",
    "                    AND 55 < temperature_surface AND temperature_surface < 75\\\n",
    "                    AND 5 >= wind_speed_gust_surface \\\n",
    "                    AND 50 < total_cloud_cover_entire_atmosphere_single_layer\")\n",
    "\n",
    "yellowstone.count()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d81117",
   "metadata": {},
   "source": [
    "### Mexico City: Touring the City\n",
    "\n",
    "Ideal Temperature: 60-85 F\n",
    "\n",
    "Wind Speed: 0-15mph\n",
    "\n",
    "Cloud Cover: 50-100%\n",
    "\n",
    "**Ideal Time: Sept**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "242befd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mexico = spark.sql(\"SELECT * from jan WHERE (geohash LIKE '9g3%')\\\n",
    "                    AND 60 <= temperature_surface AND temperature_surface <= 85\\\n",
    "                    AND 15 <= wind_speed_gust_surface \\\n",
    "                    AND 50 <= total_cloud_cover_entire_atmosphere_single_layer\")\n",
    "\n",
    "mexico.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "6135453e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mexico = spark.sql(\"SELECT * from feb WHERE (geohash LIKE '9g3%')\\\n",
    "                    AND 60 <= temperature_surface AND temperature_surface <= 85\\\n",
    "                    AND 15 <= wind_speed_gust_surface \\\n",
    "                    AND 50 <= total_cloud_cover_entire_atmosphere_single_layer\")\n",
    "\n",
    "mexico.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "279a24bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mexico = spark.sql(\"SELECT * from mar WHERE (geohash LIKE '9g3%')\\\n",
    "                    AND 60 <= temperature_surface AND temperature_surface <= 85\\\n",
    "                    AND 15 <= wind_speed_gust_surface \\\n",
    "                    AND 50 <= total_cloud_cover_entire_atmosphere_single_layer\")\n",
    "\n",
    "mexico.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "95f10579",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mexico = spark.sql(\"SELECT * from apr WHERE (geohash LIKE '9g3%')\\\n",
    "                    AND 60 <= temperature_surface AND temperature_surface <= 85\\\n",
    "                    AND 15 <= wind_speed_gust_surface \\\n",
    "                    AND 50 <= total_cloud_cover_entire_atmosphere_single_layer\")\n",
    "\n",
    "mexico.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "519301c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mexico = spark.sql(\"SELECT * from may WHERE (geohash LIKE '9g3%')\\\n",
    "                    AND 60 <= temperature_surface AND temperature_surface <= 85\\\n",
    "                    AND 15 <= wind_speed_gust_surface \\\n",
    "                    AND 50 <= total_cloud_cover_entire_atmosphere_single_layer\")\n",
    "\n",
    "mexico.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "daa11002",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mexico = spark.sql(\"SELECT * from jun WHERE (geohash LIKE '9g3%')\\\n",
    "                    AND 60 <= temperature_surface AND temperature_surface <= 85\\\n",
    "                    AND 15 <= wind_speed_gust_surface \\\n",
    "                    AND 50 <= total_cloud_cover_entire_atmosphere_single_layer\")\n",
    "\n",
    "mexico.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "a5eedf5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mexico = spark.sql(\"SELECT * from jul WHERE (geohash LIKE '9g3%')\\\n",
    "                    AND 60 <= temperature_surface AND temperature_surface <= 85\\\n",
    "                    AND 15 <= wind_speed_gust_surface \\\n",
    "                    AND 50 <= total_cloud_cover_entire_atmosphere_single_layer\")\n",
    "\n",
    "mexico.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "7a6a9e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mexico = spark.sql(\"SELECT * from aug WHERE (geohash LIKE '9g3%')\\\n",
    "                    AND 60 <= temperature_surface AND temperature_surface <= 85\\\n",
    "                    AND 15 <= wind_speed_gust_surface \\\n",
    "                    AND 50 <= total_cloud_cover_entire_atmosphere_single_layer\")\n",
    "\n",
    "mexico.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "f5088097",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mexico = spark.sql(\"SELECT * from sep WHERE (geohash LIKE '9g3%')\\\n",
    "                    AND 60 <= temperature_surface AND temperature_surface <= 85\\\n",
    "                    AND 15 <= wind_speed_gust_surface \\\n",
    "                    AND 50 <= total_cloud_cover_entire_atmosphere_single_layer\")\n",
    "\n",
    "mexico.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "7f88b64a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mexico = spark.sql(\"SELECT * from oct WHERE (geohash LIKE '9g3%')\\\n",
    "                    AND 60 <= temperature_surface AND temperature_surface <= 85\\\n",
    "                    AND 15 <= wind_speed_gust_surface \\\n",
    "                    AND 50 <= total_cloud_cover_entire_atmosphere_single_layer\")\n",
    "\n",
    "mexico.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "c4a92f3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mexico = spark.sql(\"SELECT * from nov WHERE (geohash LIKE '9g3%')\\\n",
    "                    AND 60 <= temperature_surface AND temperature_surface <= 85\\\n",
    "                    AND 15 <= wind_speed_gust_surface \\\n",
    "                    AND 50 <= total_cloud_cover_entire_atmosphere_single_layer\")\n",
    "\n",
    "mexico.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "95f0c219",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mexico = spark.sql(\"SELECT * from dec WHERE (geohash LIKE '9g3%')\\\n",
    "                    AND 60 <= temperature_surface AND temperature_surface <= 85\\\n",
    "                    AND 15 <= wind_speed_gust_surface \\\n",
    "                    AND 50 <= total_cloud_cover_entire_atmosphere_single_layer\")\n",
    "\n",
    "mexico.count()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346fbaef",
   "metadata": {},
   "source": [
    "### Portland: Hiking\n",
    "\n",
    "Ideal Temperature: 50-70 F\n",
    "\n",
    "Wind Speed: 0-10mph\n",
    "\n",
    "Cloud Cover: 40-100%\n",
    "\n",
    "**Ideal Time: May-Jun, Sept**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "93ff1779",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "355"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "portland = spark.sql(\"SELECT * from jan WHERE (geohash LIKE 'c20%')\\\n",
    "                    AND 50 <= temperature_surface AND temperature_surface <= 70\\\n",
    "                    AND 10 <= wind_speed_gust_surface \\\n",
    "                    AND 40 <= total_cloud_cover_entire_atmosphere_single_layer\")\n",
    "\n",
    "portland.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "38a2dfe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "portland = spark.sql(\"SELECT * from feb WHERE (geohash LIKE 'c20%')\\\n",
    "                    AND 50 <= temperature_surface AND temperature_surface <= 70\\\n",
    "                    AND 10 <= wind_speed_gust_surface \\\n",
    "                    AND 40 <= total_cloud_cover_entire_atmosphere_single_layer\")\n",
    "\n",
    "portland.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "03731338",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "portland = spark.sql(\"SELECT * from mar WHERE (geohash LIKE 'c20%')\\\n",
    "                    AND 50 <= temperature_surface AND temperature_surface <= 70\\\n",
    "                    AND 10 <= wind_speed_gust_surface \\\n",
    "                    AND 40 <= total_cloud_cover_entire_atmosphere_single_layer\")\n",
    "\n",
    "portland.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "21511ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "201"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "portland = spark.sql(\"SELECT * from apr WHERE (geohash LIKE 'c20%')\\\n",
    "                    AND 50 <= temperature_surface AND temperature_surface <= 70\\\n",
    "                    AND 10 <= wind_speed_gust_surface \\\n",
    "                    AND 40 <= total_cloud_cover_entire_atmosphere_single_layer\")\n",
    "\n",
    "portland.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "22e68180",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "809"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "portland = spark.sql(\"SELECT * from may WHERE (geohash LIKE 'c20%')\\\n",
    "                    AND 50 <= temperature_surface AND temperature_surface <= 70\\\n",
    "                    AND 10 <= wind_speed_gust_surface \\\n",
    "                    AND 40 <= total_cloud_cover_entire_atmosphere_single_layer\")\n",
    "\n",
    "portland.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "f5810294",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "718"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "portland = spark.sql(\"SELECT * from jun WHERE (geohash LIKE 'c20%')\\\n",
    "                    AND 50 <= temperature_surface AND temperature_surface <= 70\\\n",
    "                    AND 10 <= wind_speed_gust_surface \\\n",
    "                    AND 40 <= total_cloud_cover_entire_atmosphere_single_layer\")\n",
    "\n",
    "portland.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "d909bf8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "467"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "portland = spark.sql(\"SELECT * from jul WHERE (geohash LIKE 'c20%')\\\n",
    "                    AND 50 <= temperature_surface AND temperature_surface <= 70\\\n",
    "                    AND 10 <= wind_speed_gust_surface \\\n",
    "                    AND 40 <= total_cloud_cover_entire_atmosphere_single_layer\")\n",
    "\n",
    "portland.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "9de23890",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "358"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "portland = spark.sql(\"SELECT * from aug WHERE (geohash LIKE 'c20%')\\\n",
    "                    AND 50 <= temperature_surface AND temperature_surface <= 70\\\n",
    "                    AND 10 <= wind_speed_gust_surface \\\n",
    "                    AND 40 <= total_cloud_cover_entire_atmosphere_single_layer\")\n",
    "\n",
    "portland.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "9e50d3ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "942"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "portland = spark.sql(\"SELECT * from sep WHERE (geohash LIKE 'c20%')\\\n",
    "                    AND 50 <= temperature_surface AND temperature_surface <= 70\\\n",
    "                    AND 10 <= wind_speed_gust_surface \\\n",
    "                    AND 40 <= total_cloud_cover_entire_atmosphere_single_layer\")\n",
    "\n",
    "portland.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "63b4727c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "268"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "portland = spark.sql(\"SELECT * from oct WHERE (geohash LIKE 'c20%')\\\n",
    "                    AND 50 <= temperature_surface AND temperature_surface <= 70\\\n",
    "                    AND 10 <= wind_speed_gust_surface \\\n",
    "                    AND 40 <= total_cloud_cover_entire_atmosphere_single_layer\")\n",
    "\n",
    "portland.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "3fdf0745",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "portland = spark.sql(\"SELECT * from nov WHERE (geohash LIKE 'c20%')\\\n",
    "                    AND 50 <= temperature_surface AND temperature_surface <= 70\\\n",
    "                    AND 10 <= wind_speed_gust_surface \\\n",
    "                    AND 40 <= total_cloud_cover_entire_atmosphere_single_layer\")\n",
    "\n",
    "portland.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "557816ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "portland = spark.sql(\"SELECT * from dec WHERE (geohash LIKE 'c20%')\\\n",
    "                    AND 50 <= temperature_surface AND temperature_surface <= 70\\\n",
    "                    AND 10 <= wind_speed_gust_surface \\\n",
    "                    AND 40 <= total_cloud_cover_entire_atmosphere_single_layer\")\n",
    "\n",
    "portland.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95cae91f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8413a76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7d4763",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6dad26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
